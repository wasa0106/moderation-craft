"""
ModerationCraft Analytics Dashboard - dbtãƒ¢ãƒ‡ãƒ«è¡¨ç¤ºç‰ˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼å¯¾å¿œï¼‰
"""
import streamlit as st
import pandas as pd
import json
from datetime import datetime
from utils.database import get_connection, run_query, get_available_tables

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ModerationCraft dbt Models",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ModerationCraft dbt Models Viewer")
st.markdown("dbtã§å®šç¾©ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¾ã™ï¼ˆJSON/è¡¨å½¢å¼ï¼‰")

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
def initialize_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’åˆæœŸåŒ–"""
    conn = get_connection()
    tables = get_available_tables(conn)
    return conn, tables

# åˆæœŸåŒ–
conn, available_tables = initialize_database()

# ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜ï¼ˆéšå±¤åˆ¥ã«æ•´ç†ï¼‰
model_descriptions = {
    # === Dimension Layer ===
    'main_dimensions.dim_date': 'æ—¥ä»˜ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ - æ—¥ä»˜ãƒã‚¹ã‚¿ãƒ¼ï¼ˆ2024-2027, 1461æ—¥åˆ†ï¼‰ï¼ˆDimensionå±¤ï¼‰',
    'main_dimensions.dim_time': 'æ™‚é–“ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ - æ™‚åˆ»ãƒã‚¹ã‚¿ãƒ¼ï¼ˆ00:00-23:59, 1440åˆ†ï¼‰ï¼ˆDimensionå±¤ï¼‰',
    'main_dimensions.dim_user': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ - ãƒ¦ãƒ¼ã‚¶ãƒ¼å±æ€§ï¼ˆSCD Type 2å¯¾å¿œï¼‰ï¼ˆDimensionå±¤ï¼‰',

    # === Fact Layer ===
    'main_facts.fact_work_sessions': 'ä½œæ¥­ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¯ãƒˆ - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¿ã‚¹ã‚¯ãƒ»BigTaskåä»˜ãï¼ˆFactå±¤ï¼‰',
    'main_facts.fact_small_tasks': 'SmallTaskãƒ•ã‚¡ã‚¯ãƒˆ - ã‚¿ã‚¹ã‚¯è¨ˆç”»æƒ…å ±ï¼ˆ1ã‚¿ã‚¹ã‚¯=1ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰ï¼ˆFactå±¤ï¼‰',

    # === Staging Layer - Raw JSON ===
    'main.stg_fitbit_sleep_json': 'Fitbitç¡çœ ãƒ‡ãƒ¼ã‚¿ - ç”ŸJSONï¼ˆStagingå±¤ï¼‰',
    'main.stg_fitbit_activity_json': 'Fitbitæ´»å‹•ãƒ‡ãƒ¼ã‚¿ - ç”ŸJSONï¼ˆStagingå±¤ï¼‰',

    # === Staging Layer - Flattened ===
    'main_staging.stg_fitbit_sleep_json': 'Fitbitç¡çœ ãƒ‡ãƒ¼ã‚¿ - ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆStagingå±¤ï¼‰',
    'main_staging.stg_fitbit_activity_json': 'Fitbitæ´»å‹•ãƒ‡ãƒ¼ã‚¿ - ãƒ•ãƒ©ãƒƒãƒˆåŒ–ï¼ˆStagingå±¤ï¼‰',
    'main_staging.stg_work_sessions': 'ä½œæ¥­ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆStagingå±¤ï¼‰',
    'main_staging.stg_projects': 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒã‚¹ã‚¿ãƒ¼ï¼ˆStagingå±¤ï¼‰',
    'main_staging.stg_small_tasks': 'å°ã‚¿ã‚¹ã‚¯ãƒã‚¹ã‚¿ãƒ¼ï¼ˆStagingå±¤ï¼‰',
    'main_staging.stg_big_tasks': 'å¤§ã‚¿ã‚¹ã‚¯ï¼ˆBigTaskï¼‰ãƒã‚¹ã‚¿ãƒ¼ï¼ˆStagingå±¤ï¼‰',

    # === Intermediate Layer ===
    'main_intermediate.int_work_sessions_enriched': 'ä½œæ¥­ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¿ã‚¹ã‚¯åä»˜ãï¼‰ï¼ˆIntermediateå±¤ï¼‰',
    'main_intermediate.int_daily_health_summary': 'æ—¥æ¬¡å¥åº·ã‚µãƒãƒªãƒ¼ - å…¨ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆIntermediateå±¤ï¼‰',
    'main_intermediate.int_productivity_metrics': 'ç”Ÿç”£æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆIntermediateå±¤ï¼‰',

    # === Mart Layer ===
    'main_gold.mart_wellness_correlation': 'å¥åº·ç›¸é–¢åˆ†æï¼ˆMartå±¤ï¼‰',
    'main_gold.mart_productivity_daily': 'æ—¥æ¬¡ç”Ÿç”£æ€§ï¼ˆMartå±¤ï¼‰',

    # === BI Layer - Task Analysis ===
    'main_gold.mart_task_performance': 'ã‚¿ã‚¹ã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ - äºˆå®švså®Ÿç¸¾æ¯”è¼ƒãƒ»è¦‹ç©ã‚‚ã‚Šç²¾åº¦ï¼ˆBIå±¤ï¼‰',
    'main_gold.mart_task_completion_analysis': 'ã‚¿ã‚¹ã‚¯å®Œäº†çŠ¶æ³åˆ†æ - å®Œäº†ç‡ãƒ»æœŸé™ç®¡ç†ãƒ»æœªå®Œäº†è¿½è·¡ï¼ˆBIå±¤ï¼‰',
    'main_gold.mart_task_productivity': 'ã‚¿ã‚¹ã‚¯ç”Ÿç”£æ€§åˆ†æ - ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ»ã‚¿ã‚¤ãƒ—åˆ¥ç”Ÿç”£æ€§ï¼ˆBIå±¤ï¼‰'
}

# ãƒ¢ãƒ‡ãƒ«ã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆãƒ‡ãƒ¼ã‚¿å±¤åˆ¥ï¼‰
model_groups = {
    'Dimension Models': [
        'main_dimensions.dim_date',
        'main_dimensions.dim_time',
        'main_dimensions.dim_user',
    ],
    'Fact Models': [
        'main_facts.fact_work_sessions',
        'main_facts.fact_small_tasks',
    ],
    'Staging - Raw JSON': [
        'main.stg_fitbit_sleep_json',
        'main.stg_fitbit_activity_json',
    ],
    'Staging - Flattened': [
        'main_staging.stg_fitbit_sleep_json',
        'main_staging.stg_fitbit_activity_json',
        'main_staging.stg_work_sessions',
        'main_staging.stg_projects',
        'main_staging.stg_small_tasks',
        'main_staging.stg_big_tasks',
    ],
    'Intermediate Models': [
        'main_intermediate.int_work_sessions_enriched',
        'main_intermediate.int_daily_health_summary',
        'main_intermediate.int_productivity_metrics',
    ],
    'Mart Models': [
        'main_gold.mart_productivity_daily',
        'main_gold.mart_wellness_correlation',
    ],
    'BI - Task Analysis': [
        'main_gold.mart_task_performance',
        'main_gold.mart_task_completion_analysis',
        'main_gold.mart_task_productivity',
    ],
}

# JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã§è¡¨ç¤ºã™ã‚‹é–¢æ•°
def display_json_document(data_dict, metadata_dict, row_index, date_info=""):
    """JSONãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã‚„ã™ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã§è¡¨ç¤º"""
    with st.container():
        st.markdown(f"### Document {row_index + 1} {date_info}")
        st.markdown("---")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### Metadata")
            if metadata_dict:
                for key, value in metadata_dict.items():
                    if isinstance(value, (datetime, pd.Timestamp)):
                        value = value.strftime("%Y-%m-%d %H:%M:%S")
                    elif isinstance(value, dict):
                        value = f"{len(value)} items"
                    st.markdown(f"â€¢ **{key}**: {value}")

        with col2:
            st.markdown("#### Data Summary")
            if data_dict:
                # ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„ã‚’è¡¨ç¤º
                if 'sleep' in data_dict:
                    sleep_data = data_dict['sleep']
                    if isinstance(sleep_data, list) and len(sleep_data) > 0:
                        sleep = sleep_data[0]
                        st.markdown("**Sleep Metrics:**")
                        if 'duration' in sleep:
                            duration_hours = sleep['duration'] / 3600000 if sleep['duration'] else 0
                            st.markdown(f"â€¢ Duration: {duration_hours:.1f} hours")
                        if 'efficiency' in sleep:
                            st.markdown(f"â€¢ Efficiency: {sleep['efficiency']}%")
                        if 'minutesAsleep' in sleep:
                            st.markdown(f"â€¢ Minutes Asleep: {sleep['minutesAsleep']}")
                elif 'activities' in data_dict:
                    st.markdown("**Activity Summary:**")
                    if 'summary' in data_dict and isinstance(data_dict['summary'], dict):
                        summary = data_dict['summary']
                        if 'steps' in summary:
                            st.markdown(f"â€¢ Steps: {summary['steps']:,}")
                        if 'caloriesOut' in summary:
                            st.markdown(f"â€¢ Calories: {summary['caloriesOut']:,}")

        # JSONè©³ç´°ã‚’æŠ˜ã‚ŠãŸãŸã¿ã§è¡¨ç¤º
        with st.expander("View Full JSON"):
            col1_json, col2_json = st.columns(2)
            with col1_json:
                st.markdown("**Metadata:**")
                st.json(metadata_dict)
            with col2_json:
                st.markdown("**Data:**")
                st.json(data_dict)

        st.markdown("---")

# åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
with st.sidebar:
    st.header("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±")

    # å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—ã—ã¦è¡¨ç¤º
    st.markdown("### å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«")
    if available_tables:
        # ã‚¹ã‚­ãƒ¼ãƒä»˜ããƒ†ãƒ¼ãƒ–ãƒ«åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        schema_tables = []
        try:
            schema_df = conn.execute("""
                SELECT table_schema || '.' || table_name as full_name
                FROM information_schema.tables
                WHERE table_schema NOT IN ('information_schema', 'pg_catalog')
                ORDER BY table_schema, table_name
            """).df()
            schema_tables = schema_df['full_name'].tolist()
        except:
            schema_tables = available_tables

        for table in schema_tables:
            status = "[OK]" if table in model_descriptions else "[?]"
            st.markdown(f"{status} `{table}`")
        st.success(f"åˆè¨ˆ {len(schema_tables)} ãƒ†ãƒ¼ãƒ–ãƒ«")
    else:
        st.warning("ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    st.markdown("---")
    st.markdown("### ãƒ‡ãƒ¼ã‚¿å±¤ã®èª¬æ˜")
    st.markdown("""
    **main.**: ç”ŸJSONãƒ‡ãƒ¼ã‚¿ï¼ˆS3ã‹ã‚‰ç›´æ¥ï¼‰
    **main_staging**: ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
    **main_dimensions**: ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
    **main_facts**: ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰
    **main_intermediate**: ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯é©ç”¨
    **main_gold**: åˆ†æç”¨é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    """)

    st.markdown("---")
    st.info("å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ä¸­")

# ã‚¿ãƒ–ä½œæˆï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ï¼‰
tabs = st.tabs(list(model_groups.keys()))

# å„ã‚¿ãƒ–ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
for group_name, tab in zip(model_groups.keys(), tabs):
    with tab:
        st.header(group_name)
        st.markdown("---")

        # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å„ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
        for table_name in model_groups[group_name]:
            st.subheader(f"{model_descriptions[table_name]}")
            st.markdown(f"**ãƒ†ãƒ¼ãƒ–ãƒ«å**: `{table_name}`")

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
            is_json_table = table_name.startswith('main.') and 'json' in table_name
            is_dimension_table = table_name.startswith('main_dimensions.')
            is_fact_table = table_name.startswith('main_facts.')

            if is_dimension_table:
                st.info("ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰")
            elif is_fact_table:
                st.info("ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰")
            elif is_json_table:
                st.info("ç”Ÿã®JSONãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã§è¡¨ç¤ºï¼‰")

            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            query = f"SELECT * FROM {table_name} LIMIT 100"

            try:
                df = run_query(query, conn)

                if df is not None and not df.empty:
                    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        # å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—
                        count_query = f"SELECT COUNT(*) as total FROM {table_name}"
                        count_df = run_query(count_query, conn)
                        total_count = count_df['total'].iloc[0] if not count_df.empty else len(df)
                        st.metric("ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°", f"{total_count:,}")
                    with col2:
                        st.metric("ã‚«ãƒ©ãƒ æ•°", len(df.columns))
                    with col3:
                        if is_dimension_table:
                            st.metric("è¡¨ç¤ºä»¶æ•°", f"{len(df):,} (å…¨ä»¶)")
                        elif is_json_table:
                            st.metric("è¡¨ç¤ºä»¶æ•°", min(5, len(df)))
                        else:
                            st.metric("è¡¨ç¤ºä»¶æ•°", min(30, len(df)))

                    # ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã®å ´åˆã¯å…¨ä»¶è¡¨ç¤º
                    if is_dimension_table:
                        st.markdown("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…¨ä»¶è¡¨ç¤ºï¼‰")

                        # ä¸»ã‚­ãƒ¼ã‚«ãƒ©ãƒ ã‚’æ¤œå‡º
                        key_columns = [col for col in df.columns if '_key' in col.lower() or col.lower() == 'id']

                        # ã‚«ãƒ©ãƒ æƒ…å ±
                        with st.expander("ã‚«ãƒ©ãƒ æƒ…å ±"):
                            unique_counts = []
                            for col in df.columns:
                                try:
                                    unique_counts.append(df[col].nunique())
                                except:
                                    unique_counts.append('N/A')

                            column_info = pd.DataFrame({
                                'ã‚«ãƒ©ãƒ å': df.columns,
                                'ãƒ‡ãƒ¼ã‚¿å‹': df.dtypes.astype(str),
                                'NULLå€¤': df.isnull().sum(),
                                'ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤': unique_counts,
                                'ä¸»ã‚­ãƒ¼': ['ğŸ”‘' if col in key_columns else '' for col in df.columns]
                            })
                            st.dataframe(column_info, use_container_width=True)

                        # å…¨ä»¶è¡¨ç¤ºï¼ˆãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã¯é€šå¸¸å°ã•ã„ï¼‰
                        st.dataframe(
                            df,
                            use_container_width=True,
                            height=min(600, len(df) * 35 + 38)
                        )

                        # çµ±è¨ˆæƒ…å ±
                        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
                        if len(numeric_columns) > 0:
                            with st.expander("çµ±è¨ˆã‚µãƒãƒªãƒ¼"):
                                st.dataframe(
                                    df[numeric_columns].describe().round(2),
                                    use_container_width=True
                                )

                    # ãƒ•ã‚¡ã‚¯ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã®å ´åˆã¯é›†è¨ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã§è¡¨ç¤º
                    elif is_fact_table:
                        st.markdown("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

                        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ©ãƒ ã¨ãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã‚«ãƒ©ãƒ ã‚’åˆ†é›¢
                        metric_columns = [col for col in df.columns if any(keyword in col.lower()
                                         for keyword in ['duration', 'score', 'level', 'rating', 'minutes', 'seconds'])]
                        dimension_columns = [col for col in df.columns if '_key' in col.lower() or
                                           col.lower() in ['project_id', 'small_task_id', 'user_id']]

                        # ã‚«ãƒ©ãƒ æƒ…å ±
                        with st.expander("ã‚«ãƒ©ãƒ æƒ…å ±"):
                            unique_counts = []
                            for col in df.columns:
                                try:
                                    unique_counts.append(df[col].nunique())
                                except:
                                    unique_counts.append('N/A')

                            column_type = []
                            for col in df.columns:
                                if col in metric_columns:
                                    column_type.append('[Metric]')
                                elif col in dimension_columns:
                                    column_type.append('[Dimension]')
                                else:
                                    column_type.append('[Attribute]')

                            column_info = pd.DataFrame({
                                'ã‚«ãƒ©ãƒ å': df.columns,
                                'ã‚¿ã‚¤ãƒ—': column_type,
                                'ãƒ‡ãƒ¼ã‚¿å‹': df.dtypes.astype(str),
                                'NULLå€¤': df.isnull().sum(),
                                'ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤': unique_counts
                            })
                            st.dataframe(column_info, use_container_width=True)

                        # ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ã¦Sliderã‚’è¡¨ç¤º
                        if len(df) > 5:
                            n_rows = st.slider(
                                "è¡¨ç¤ºã™ã‚‹è¡Œæ•°",
                                min_value=5,
                                max_value=100,
                                value=min(30, len(df)),
                                step=5,
                                key=f"slider_{table_name}"
                            )
                        else:
                            n_rows = len(df)

                        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                        st.dataframe(
                            df.head(n_rows),
                            use_container_width=True,
                            height=400
                        )

                        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®çµ±è¨ˆæƒ…å ±
                        if metric_columns:
                            with st.expander("ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ"):
                                st.dataframe(
                                    df[metric_columns].describe().round(2),
                                    use_container_width=True
                                )

                    # JSONãƒ†ãƒ¼ãƒ–ãƒ«ã®å ´åˆã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã§è¡¨ç¤º
                    elif is_json_table:
                        st.markdown("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ï¼‰")

                        # æœ€å¤§5ä»¶ã¾ã§è¡¨ç¤º
                        display_count = min(5, len(df))

                        # è¾æ›¸å‹ã‚«ãƒ©ãƒ ã‚’æ¤œå‡º
                        dict_columns = []
                        for col in df.columns:
                            if not df[col].isna().all():
                                sample = df[col].dropna().iloc[0] if not df[col].dropna().empty else None
                                if isinstance(sample, dict):
                                    dict_columns.append(col)

                        if dict_columns:
                            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã§è¡¨ç¤º
                            for i in range(display_count):
                                row = df.iloc[i]

                                # æ—¥ä»˜æƒ…å ±ã‚’å–å¾—
                                date_info = ""
                                if 'year' in df.columns and 'month' in df.columns and 'day' in df.columns:
                                    date_info = f"- {row['year']}/{row['month']}/{row['day']}"

                                # metadata ã¨ data ã‚’å–å¾—
                                metadata = row.get('metadata', {}) if 'metadata' in row else {}
                                data = row.get('data', {}) if 'data' in row else {}

                                # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¡¨ç¤º
                                display_json_document(data, metadata, i, date_info)
                        else:
                            # è¾æ›¸å‹ã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¯é€šå¸¸ã®è¡¨å½¢å¼
                            st.dataframe(df.head(display_count), use_container_width=True)

                    # ãã®ä»–ã®ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆstagingãƒ•ãƒ©ãƒƒãƒˆåŒ–ã€intermediateï¼‰ã¯è¡¨å½¢å¼ã§è¡¨ç¤º
                    else:
                        st.markdown("### ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")

                        # ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ã¦Sliderã‚’è¡¨ç¤ºï¼ˆãƒ¬ã‚³ãƒ¼ãƒ‰ãŒ5ä»¶ä»¥ä¸Šã®å ´åˆã®ã¿ï¼‰
                        if len(df) > 5:
                            n_rows = st.slider(
                                "è¡¨ç¤ºã™ã‚‹è¡Œæ•°",
                                min_value=5,
                                max_value=100,
                                value=min(30, len(df)),
                                step=5,
                                key=f"slider_{table_name}"
                            )
                        else:
                            n_rows = len(df)
                            st.info(f"å…¨{n_rows}ä»¶ã‚’è¡¨ç¤ºä¸­")

                        # ã‚«ãƒ©ãƒ æƒ…å ±
                        with st.expander("ã‚«ãƒ©ãƒ æƒ…å ±"):
                            # ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤ã‚’å®‰å…¨ã«è¨ˆç®—
                            unique_counts = []
                            for col in df.columns:
                                try:
                                    sample_value = df[col].dropna().iloc[0] if not df[col].dropna().empty else None
                                    if isinstance(sample_value, dict):
                                        unique_counts.append('STRUCTå‹')
                                    else:
                                        unique_counts.append(df[col].nunique())
                                except:
                                    unique_counts.append('N/A')

                            column_info = pd.DataFrame({
                                'ã‚«ãƒ©ãƒ å': df.columns,
                                'ãƒ‡ãƒ¼ã‚¿å‹': df.dtypes.astype(str),
                                'NULLå€¤': df.isnull().sum(),
                                'ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤': unique_counts
                            })
                            st.dataframe(column_info, use_container_width=True)

                        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                        st.dataframe(
                            df.head(n_rows),
                            use_container_width=True,
                            height=400
                        )

                        # çµ±è¨ˆæƒ…å ±ï¼ˆæ•°å€¤ã‚«ãƒ©ãƒ ã®ã¿ï¼‰
                        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns
                        if len(numeric_columns) > 0:
                            with st.expander("çµ±è¨ˆã‚µãƒãƒªãƒ¼"):
                                st.dataframe(
                                    df[numeric_columns].describe().round(2),
                                    use_container_width=True
                                )

                else:
                    st.warning(f"{table_name} ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                    with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
                        st.code(query)

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)[:200]}")

                # ã‚¨ãƒ©ãƒ¼è©³ç´°
                with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                    st.code(str(e))
                    st.markdown("**å®Ÿè¡Œã—ã‚ˆã†ã¨ã—ãŸã‚¯ã‚¨ãƒª:**")
                    st.code(query)

                    # ãƒ’ãƒ³ãƒˆè¡¨ç¤º
                    if "does not exist" in str(e).lower():
                        st.info("ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

            # ãƒ¢ãƒ‡ãƒ«é–“ã®åŒºåˆ‡ã‚Šç·š
            st.markdown("---")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.caption("ModerationCraft dbt Models Viewer | å®Ÿãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºä¸­ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ/è¡¨å½¢å¼ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰")