# データパイプライン管理機能

## 概要

データパイプライン管理機能は、ModerationCraftのデータをAWS S3に自動エクスポートし、分析基盤を構築するための機能です。DynamoDBに保存されているアプリケーションデータを定期的にS3データレイクにエクスポートし、将来的な分析やレポート生成に活用します。

## アクセス方法

デバッグメニューから「データパイプライン管理」にアクセス:
- URL: `/debug/pipeline`
- サイドバー: デバッグ → パイプライン

## 画面構成

### ヘッダーセクション

#### タイトルエリア
- **データパイプライン管理**: メインタイトル
- **説明文**: DynamoDB → S3 エクスポートの管理とモニタリング

#### アクションボタン
- **更新ボタン**: エクスポート履歴を最新の状態に更新
- **手動エクスポートボタン**: Lambda関数を即座に実行してデータをエクスポート

### ステータスタブ

#### エクスポート結果表示
手動エクスポートを実行した際の結果をリアルタイムで表示します。

**表示内容**:
- ステータスコード（200: 成功、500: エラー）
- 実行メッセージ
- エクスポートされたレコード数
- S3保存先パス

#### 統計カード

3つのメトリクスカードで現在の状況を一目で確認できます。

| カード | 内容 | 説明 |
|--------|------|------|
| **総エクスポート数** | 実行回数 | 過去7日間のエクスポート実行回数 |
| **最終エクスポート** | 日付 | 最後にエクスポートが実行された日付 |
| **データサイズ** | ファイルサイズ | 最新エクスポートファイルのサイズ |

### 履歴タブ

過去のエクスポート履歴を時系列で確認できます。

#### 履歴リスト

各エクスポートの詳細情報:
- **テーブル名**: エクスポート元のDynamoDBテーブル
- **実行日時**: 日本時間でフォーマットされた実行時刻
- **ファイルサイズ**: エクスポートされたJSONファイルのサイズ
- **ダウンロードボタン**: 最新データのJSON形式ダウンロード

#### データ保持期間
- デフォルト: 過去7日間
- S3上のデータ: 30日後にStandard IAへ移行、90日後にGlacierへアーカイブ

### 設定タブ

現在のAWS設定と構成を確認できます。

| 項目 | 値 | 説明 |
|------|-----|------|
| **S3バケット** | moderation-craft-data-800860245583 | データ保存先 |
| **Lambda関数** | moderation-craft-export-dynamodb | エクスポート実行関数 |
| **スケジュール** | 毎日 14:00 JST | 自動実行時刻 |
| **DynamoDBテーブル** | moderation-craft-data | エクスポート元 |
| **AWSリージョン** | ap-northeast-1 | 東京リージョン |

## 使用方法

### 1. 日次エクスポートの確認

毎日14:00に自動実行されるエクスポートの状況を確認：

1. ステータスタブを開く
2. 「最終エクスポート」カードで実行日を確認
3. 履歴タブで詳細な実行履歴を確認

### 2. 手動エクスポートの実行

レポート作成前など、最新データが必要な場合：

1. 「手動エクスポート」ボタンをクリック
2. ボタンがスピナー表示になり、処理中であることを示す
3. 完了後、結果がカードで表示される
4. エラーの場合は赤色のエラーメッセージが表示

### 3. データのダウンロード

分析用にエクスポートデータをローカルに保存：

1. 履歴タブを開く
2. ダウンロードしたいエクスポートの行を確認
3. ダウンロードアイコンをクリック
4. JSON形式でファイルがダウンロードされる

### 4. エラーの対処

エラーが発生した場合の確認手順：

1. エラーメッセージを確認（赤色のカード）
2. 設定タブでAWS設定を確認
3. 必要に応じて環境変数を確認

## データ形式

### エクスポートファイル構造

```json
{
  "export_metadata": {
    "table_name": "moderation-craft-data",
    "exported_at": "2024-02-01T12:00:00Z",
    "export_version": "1.0",
    "record_count": 100
  },
  "data": [
    {
      "id": "xxx",
      "created_at": "2024-01-15T10:00:00Z",
      "_exported_at": "2024-02-01T12:00:00Z"
    }
  ]
}
```

### S3ディレクトリ構造

```
s3://moderation-craft-data-800860245583/
└── raw/
    └── internal/
        └── dynamodb-exports/
            └── dt=2024-02-01/
                └── moderation-craft-data.json
```

## トラブルシューティング

### よくある問題と解決方法

| 問題 | 原因 | 解決方法 |
|------|------|---------|
| 「認証エラー」 | AWS認証情報が無効 | .env.localのAWS_ACCESS_KEY_IDとAWS_SECRET_ACCESS_KEYを確認 |
| 「タイムアウト」 | データ量が多すぎる | Lambda関数のタイムアウト設定を延長（AWSコンソール） |
| 「履歴が表示されない」 | S3アクセス権限不足 | IAMロールの権限を確認 |
| 「手動エクスポートが失敗」 | Lambda関数エラー | CloudWatchログで詳細を確認 |

### ログの確認方法

AWS CloudWatchでLambda関数のログを確認：
```bash
aws logs tail /aws/lambda/moderation-craft-export-dynamodb --follow
```

## セキュリティ

### アクセス制御
- デバッグページのため、本番環境では適切なアクセス制御を実装
- AWS認証情報は環境変数で管理し、コードに直接記載しない

### データ保護
- S3バケットは暗号化有効（AES256）
- エクスポートデータは転送時もHTTPS使用
- IAMロールは最小権限の原則に従う

## 今後の拡張予定

### Phase 2（外部連携）
- Fitbitデータの統合
- 天候データの取り込み
- 複数データソースの管理UI

### Phase 3（分析基盤）
- DuckDBによるブラウザ内分析
- dbtモデルの実行状況表示
- データ品質チェック結果の表示

### Phase 4（高度な分析）
- 相関分析ダッシュボード
- 予測モデルの実行結果表示
- カスタムレポート生成

## 関連ドキュメント

- [Phase 1: 基盤構築](/docs/data-pipeline/phase-1-infrastructure.md)
- [Phase 1: 統合実装](/docs/data-pipeline/phase-1-integration.md)
- [技術仕様書](/docs/data-pipeline/technical-specifications.md)
- [テスト戦略](/docs/data-pipeline/testing-strategy.md)

---

*最終更新: 2024年2月*
*作成者: ModerationCraft開発チーム*